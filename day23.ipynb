{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 23\n",
    "\n",
    "https://adventofcode.com/2021/day/23\n",
    "\n",
    "Initially I tried Q-learning for this (at the end of the notebook), which was able to learn a decent strategy but not find the best one. So I built a network with a node for each possible state of the game, and an edge between nodes i and j if there is a valid move that goes from state i to state j. The edges are weighted by the energy cost of the moves. The Dijkstra algorithm in networkx then finds the series of moves ending at the winning state with lowest energy cost.\n",
    "\n",
    "The problem imposes three restrictions on moves that significantly reduce the number of possible states. I added two further conditions:\n",
    "* An amphipod cannot leave its home unless there is an incorrect amphipod below it. \n",
    "* When returning home, an amphipod must go to the lowest available space.\n",
    "\n",
    "Neither of these are required by the rules, but the sequence of moves with lowest energy cost will always meet these two conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test = [\"#############\", \n",
    "\"#...........#\", \n",
    "\"###B#C#B#D###\", \n",
    "\"  #A#D#C#A#  \", \n",
    "\"  #########  \"]\n",
    "\n",
    "raw = [\"#############\",\n",
    "\"#...........#\",\n",
    "\"###C#A#B#D###\",\n",
    "\"  #C#A#D#B#  \",\n",
    "\"  #########  \"]\n",
    "\n",
    "raw_extended = [\"#############\",\n",
    "\"#...........#\",\n",
    "\"###C#A#B#D###\",\n",
    "\"  #D#C#B#A#  \",\n",
    "\"  #D#B#A#C#  \",\n",
    "\"  #C#A#D#B#  \",\n",
    "\"  #########  \"]\n",
    "\n",
    "finished_test = [\"#############\", \n",
    "\"#...........#\", \n",
    "\"###A#B#C#D###\", \n",
    "\"  #A#B#C#D#  \", \n",
    "\"  #########  \"]\n",
    "\n",
    "finished_test_extended = [\"#############\", \n",
    "\"#...........#\", \n",
    "\"###A#B#C#D###\", \n",
    "\"  #A#B#C#D#  \", \n",
    "\"  #A#B#C#D#  \", \n",
    "\"  #A#B#C#D#  \", \n",
    "\"  #########  \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates a map of the game with a symbol (in 0-9 or V-T) for each place that an amphipod can stand. Then it creates a dictionary of paths between each pair of places. The dictionary stores the length of the path and any places in between the end points that could block the path if there's an amphipod there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': [(2, 7), (1, 7), (1, 6), (1, 5), (1, 4), (1, 3), (1, 2), (1, 1)],\n",
       " 'path_length': 8,\n",
       " 'blocking_locations': ['9', '3', '2', '1', '0']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "room_map = np.array([['#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#'],\n",
    "       ['#', '0', '1', '.', '2', '.', '3', '.', '4', '.', '5', '6', '#'],\n",
    "       ['#', '#', '#', '7', '#', '8', '#', '9', '#', 'V', '#', '#', '#'],\n",
    "       [' ', ' ', '#', 'W', '#', 'X', '#', 'Y', '#', 'Z', '#', ' ', ' '],\n",
    "       [' ', ' ', '#', 'M', '#', 'N', '#', 'O', '#', 'P', '#', ' ', ' '],\n",
    "       [' ', ' ', '#', 'Q', '#', 'R', '#', 'S', '#', 'T', '#', ' ', ' '],\n",
    "       [' ', ' ', '#', '#', '#', '#', '#', '#', '#', '#', '#', ' ', ' ']],\n",
    "      dtype='<U1')\n",
    "\n",
    "all_locations = \"0123456789VWXYZMNOPQRST\"\n",
    "corridor_locations = list(\"0123456\")\n",
    "room_locations = list(\"789VWXYZMNPQRST\")\n",
    "\n",
    "def all_indices(array, element):\n",
    "    w = np.where(array == element)\n",
    "    return list(zip(w[0], w[1]))\n",
    "\n",
    "def first_index(array, element):\n",
    "    return all_indices(array, element)[0]\n",
    "\n",
    "\n",
    "location_indices = {x: first_index(room_map, x) for x in all_locations}\n",
    "\n",
    "node_attributes = {}\n",
    "G = nx.Graph()\n",
    "for i in range(1, room_map.shape[0] - 1):\n",
    "    for j in range(1, room_map.shape[1] - 1):\n",
    "        square = room_map[i, j]\n",
    "        if square not in [\"#\", \" \"]:\n",
    "            G.add_node((i, j))\n",
    "            if room_map[i - 1, j] not in [\"#\", \" \"]:\n",
    "                G.add_edge((i - 1, j), (i, j))\n",
    "            if room_map[i, j - 1] not in [\"#\", \" \"]:\n",
    "                G.add_edge((i, j - 1), (i, j))\n",
    "            \n",
    "            if square in all_locations:\n",
    "                node_attributes[(i, j)] = {\"location\": square}\n",
    "                \n",
    "nx.set_node_attributes(G, node_attributes)\n",
    "\n",
    "all_paths = {}\n",
    "for l_0 in all_locations:\n",
    "    for l_1 in all_locations:\n",
    "        path = nx.shortest_path(G, first_index(room_map, l_0), first_index(room_map, l_1))[1:]\n",
    "        path_length = len(path)\n",
    "        blocking_locations = []\n",
    "        for p in path:\n",
    "            if \"location\" in G.nodes[p]:\n",
    "                blocking_locations.append(G.nodes[p][\"location\"])\n",
    "               \n",
    "        all_paths[(l_0, l_1)] = {\"path\": path, \"path_length\": path_length, \"blocking_locations\": blocking_locations}\n",
    " \n",
    "all_paths[(\"Y\", \"0\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amphipod class stores information about each amphipod. The valid_moves method returns places it can move to, implementing the following conditions:\n",
    "\n",
    "* If in the corridor, it can return to its home\n",
    "* If at home and has not moved yet, it can move to the corridor\n",
    "* If at home and has already moved, cannot move again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_costs = {\"A\": -1, \"B\": -10, \"C\": -100, \"D\": -1000}\n",
    "     \n",
    "home_locations_ordered = {\"A\": [\"Q\", \"M\", \"W\", \"7\"], \n",
    "                  \"B\": [\"R\", \"N\", \"X\", \"8\"], \n",
    "                  \"C\": [\"S\", \"O\", \"Y\", \"9\"], \n",
    "                  \"D\": [\"T\", \"P\", \"Z\", \"V\"]}\n",
    "    \n",
    "home_locations = {l: set(home_locations_ordered[l]) for l in \"ABCD\"}\n",
    "\n",
    "other_room_locations = dict()\n",
    "for room in home_locations_ordered.values():\n",
    "    for square in room:\n",
    "        other_room_locations[square] = room\n",
    "    \n",
    "    \n",
    "class Amphipod:\n",
    "    \n",
    "    def __init__(self, i, letter, position):\n",
    "        self.id = i\n",
    "        self.letter = letter\n",
    "        self.position = position\n",
    "        self.energy_per_step = energy_costs[self.letter]\n",
    "        self.home_locations = home_locations[self.letter]\n",
    "        self.returned_home = False\n",
    "        \n",
    "    def filter_home_locations(self, valid_locations):\n",
    "        self.home_locations = set([x for x in self.home_locations if x in valid_locations])\n",
    "        \n",
    "    def move(self, move):\n",
    "        move_length = all_paths[(self.position, move)][\"path_length\"]\n",
    "        self.position = move\n",
    "        if self.is_at_home():\n",
    "            self.returned_home = True\n",
    "        return self.energy_per_step * move_length\n",
    "        \n",
    "    def is_at_home(self):\n",
    "        return self.position in self.home_locations\n",
    "    \n",
    "    def is_in_wrong_room(self):\n",
    "        return self.position in room_locations and not self.is_at_home()\n",
    "    \n",
    "    def is_in_corridor(self):\n",
    "        return self.position in corridor_locations\n",
    "    \n",
    "    def valid_moves(self):\n",
    "        if self.returned_home:\n",
    "            return []\n",
    "        elif self.is_in_corridor():\n",
    "            return [(self.position, b) for b in self.home_locations]\n",
    "        else:\n",
    "            return [(self.position, b) for b in corridor_locations]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AmphipodEnvironment keeps track of the game state. The valid_moves method lists the valid_moves from each Amphipod, then filters them to add the following conditions:\n",
    "\n",
    "* the path must be clear\n",
    "* if the amphipod is at home, it can only move if there is an incorrect amphipod below it\n",
    "* cannot return home if there is an incorrect amphipod there\n",
    "* when returning home, must go to the lowest available space\n",
    "\n",
    "The state_to_str method concatenates the state to a single string, used as a unique identifier for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmphipodEnvironment:\n",
    "    \n",
    "    def __init__(self, initial_state):\n",
    "        self.room_locations = []\n",
    "        self.won = False\n",
    "        self.state = np.array([list(l) for l in initial_state], dtype = str)\n",
    "        \n",
    "        i = 0\n",
    "        self.amphipods = []\n",
    "        for letter in \"ABCD\":\n",
    "            idxs = all_indices(self.state, letter)\n",
    "            for idx in idxs:\n",
    "                location = room_map[idx]\n",
    "                self.room_locations.append(location)\n",
    "                self.amphipods.append(Amphipod(i, letter, location))\n",
    "                i = i + 1\n",
    "        \n",
    "        for a in self.amphipods:\n",
    "            a.filter_home_locations(self.room_locations)\n",
    "        \n",
    "        self.blocked_locations = {x: True for x in self.room_locations}\n",
    "        self.blocked_locations.update({x: False for x in corridor_locations})\n",
    "        self.other_room_locations = {\n",
    "            x: [y for y in other_room_locations[x] if y in self.room_locations] for x in other_room_locations\n",
    "        }\n",
    "        self.cost = 0\n",
    "    \n",
    "    def check_valid_room_location(self, loc):\n",
    "        other_room_locations = self.other_room_locations[loc]\n",
    "        if any([a.position in other_room_locations and a.is_in_wrong_room() for a in self.amphipods]):\n",
    "            return False\n",
    "        \n",
    "        for other_loc in other_room_locations:\n",
    "            if other_loc == loc:\n",
    "                return True\n",
    "            \n",
    "            elif not any([a.position == other_loc for a in self.amphipods]):\n",
    "                return False\n",
    "    \n",
    "    def state_to_str(self):\n",
    "        statestr = self.state[1:-1, 1:-1]\n",
    "        statestr = statestr.reshape(statestr.size)\n",
    "        return ''.join(statestr)\n",
    "    \n",
    "    def valid_moves(self):\n",
    "        res = []\n",
    "        for a in self.amphipods:\n",
    "            valid_moves = a.valid_moves()\n",
    "            disqualified_moves = []\n",
    "            \n",
    "            for move in valid_moves:\n",
    "                \n",
    "                # check path is clear\n",
    "                if any([self.blocked_locations[b] for b in all_paths[move][\"blocking_locations\"]]):\n",
    "                    disqualified_moves.append(move)\n",
    "                    continue\n",
    "                \n",
    "                # if at home, check that home has incorrect amphipods\n",
    "                elif move[1] in corridor_locations:\n",
    "                    if self.check_valid_room_location(a.position):\n",
    "                        disqualified_moves.append(move)\n",
    "                        continue\n",
    "                \n",
    "                # if returning home, check that home has no incorrect amphipods, \n",
    "                # and that destination is the lowest available point\n",
    "                elif move[1] in self.room_locations:\n",
    "                    if not self.check_valid_room_location(move[1]):\n",
    "                        disqualified_moves.append(move)\n",
    "                        \n",
    "            valid_moves = [move for move in valid_moves if move not in disqualified_moves]\n",
    "            \n",
    "            res = res + valid_moves\n",
    "            \n",
    "        return res\n",
    "                    \n",
    "                \n",
    "    def step(self, move):\n",
    "        \n",
    "        a = [a for a in self.amphipods if a.position == move[0]][0]\n",
    "        p = move[1]\n",
    "        \n",
    "        self.state[location_indices[a.position]] = \".\"\n",
    "        self.blocked_locations[a.position] = False\n",
    "        \n",
    "        self.state[location_indices[p]] = a.letter\n",
    "        self.blocked_locations[p] = True\n",
    "        \n",
    "        reward = a.move(p)\n",
    "        \n",
    "        self.cost = self.cost + reward\n",
    "        \n",
    "        done = all([a.is_at_home() for a in self.amphipods])\n",
    "        \n",
    "        if done:\n",
    "            self.won = True\n",
    "        \n",
    "        return (self.state_to_str(), reward, done, a.returned_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def build_game_graph(G, env, debug = True):\n",
    "    \"\"\"Recursive function to build a graph of all possible states in the game, with weighted edges representing\n",
    "    valid moves between states.\"\"\"\n",
    "    valid_moves = env.valid_moves()\n",
    "    if len(valid_moves) == 0:\n",
    "        return\n",
    "    i = env.state_to_str()\n",
    "    for move in valid_moves:\n",
    "        if debug:\n",
    "            print(move)\n",
    "        new_env = copy.deepcopy(env)\n",
    "        j, reward, done, _ = new_env.step(move)\n",
    "        if j not in G.nodes:\n",
    "            G.add_node(j)\n",
    "            build_game_graph(G, new_env, debug = False)\n",
    "            \n",
    "        G.add_edge(i, j)\n",
    "        nx.set_edge_attributes(G, {(i, j): {\"weight\": -reward}})\n",
    "    return\n",
    "\n",
    "def shortest_path(G, start, end):\n",
    "    \"\"\"Use Dijkstra algorithm to find the shortest weighted path between states 'start' and 'end' on graph G.\"\"\"\n",
    "    start_node = AmphipodEnvironment(start).state_to_str()\n",
    "    end_node = AmphipodEnvironment(end).state_to_str()\n",
    "    paths = nx.dijkstra_path(G, start_node, end_node)\n",
    "    path_edges = [G.edges[e] for e in zip(paths[:-1], paths[1:])]\n",
    "    return sum([x[\"weight\"] for x in path_edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('8', '0')\n",
      "('8', '1')\n",
      "('8', '2')\n",
      "('8', '3')\n",
      "('8', '4')\n",
      "('8', '5')\n",
      "('8', '6')\n",
      "('9', '0')\n",
      "('9', '1')\n",
      "('9', '2')\n",
      "('9', '3')\n",
      "('9', '4')\n",
      "('9', '5')\n",
      "('9', '6')\n",
      "('7', '0')\n",
      "('7', '1')\n",
      "('7', '2')\n",
      "('7', '3')\n",
      "('7', '4')\n",
      "('7', '5')\n",
      "('7', '6')\n",
      "('V', '0')\n",
      "('V', '1')\n",
      "('V', '2')\n",
      "('V', '3')\n",
      "('V', '4')\n",
      "('V', '5')\n",
      "('V', '6')\n"
     ]
    }
   ],
   "source": [
    "env = AmphipodEnvironment(raw)\n",
    "G = nx.Graph()\n",
    "\n",
    "G.add_node(env.state_to_str())    \n",
    "build_game_graph(G, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path(G, raw, finished_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('8', '0')\n",
      "('8', '1')\n",
      "('8', '2')\n",
      "('8', '3')\n",
      "('8', '4')\n",
      "('8', '5')\n",
      "('8', '6')\n",
      "('9', '0')\n",
      "('9', '1')\n",
      "('9', '2')\n",
      "('9', '3')\n",
      "('9', '4')\n",
      "('9', '5')\n",
      "('9', '6')\n",
      "('7', '0')\n",
      "('7', '1')\n",
      "('7', '2')\n",
      "('7', '3')\n",
      "('7', '4')\n",
      "('7', '5')\n",
      "('7', '6')\n",
      "('V', '0')\n",
      "('V', '1')\n",
      "('V', '2')\n",
      "('V', '3')\n",
      "('V', '4')\n",
      "('V', '5')\n",
      "('V', '6')\n"
     ]
    }
   ],
   "source": [
    "env = AmphipodEnvironment(raw_extended)\n",
    "G = nx.Graph()\n",
    "\n",
    "G.add_node(env.state_to_str())\n",
    "\n",
    "build_game_graph(G, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path(G, raw_extended, finished_test_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q Learning\n",
    "\n",
    "Below is the Q-learning code. The penalty for each move is the energy cost of the movement. There is a penalty of 50,000 for getting into a situation with no valid moves. There is a reward of 100,000 for winning the game. The algorithm can learn a decent strategy but does not find the best strategy, at least with this number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 10000\n",
      "Episode: 20000\n",
      "Episode: 30000\n",
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.2\n",
    "gamma = 0.6\n",
    "epsilon = 0.2\n",
    "\n",
    "# Q table\n",
    "q_table = {}\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = [] \n",
    "all_penalties = []\n",
    "\n",
    "for i in range(1, 30001):\n",
    "    env = AmphipodEnvironment(raw_test)\n",
    "    state = env.state_to_str()\n",
    "    \n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        if state not in q_table:\n",
    "            q_table[state] = {x: 0 for x in env.valid_moves()}\n",
    "        \n",
    "        action_space = {x: q_table[state][x] for x in env.valid_moves()}   \n",
    "                \n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action = list(action_space.keys())[np.random.randint(len(action_space))] # Explore action space\n",
    "        else:\n",
    "            action = list(action_space.keys())[np.argmax(list(action_space.values()))] # Exploit learned values\n",
    "\n",
    "        next_state, reward, done, returned_home = env.step(action) \n",
    "        \n",
    "        old_value = action_space[action]\n",
    "        \n",
    "        if next_state not in q_table:\n",
    "            q_table[next_state] = {x: 0 for x in env.valid_moves()}\n",
    "        \n",
    "        next_valid_moves = {x: q_table[next_state][x] for x in env.valid_moves()}  \n",
    "        \n",
    "        if env.won:\n",
    "            next_max = 0\n",
    "            reward = reward + 100000\n",
    "            done = True\n",
    "        elif len(next_valid_moves) == 0:\n",
    "            next_max = 0\n",
    "            reward = reward - 50000\n",
    "            done = True\n",
    "        else:\n",
    "            next_max = np.max(list(next_valid_moves.values()))\n",
    "        \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state][action] = new_value\n",
    "\n",
    "        state = next_state\n",
    "        epochs += 1\n",
    "        \n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' '.' '.' '.' '.' '.' '.' '#']\n",
      " ['#' '#' '#' '.' '#' 'C' '#' 'B' '#' 'D' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' 'A' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' '.' '.' '.' '.' '.' 'B' '#']\n",
      " ['#' '#' '#' '.' '#' 'C' '#' '.' '#' 'D' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' 'A' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' 'C' '.' '.' '.' '.' 'B' '#']\n",
      " ['#' '#' '#' '.' '#' '.' '#' '.' '#' 'D' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' 'A' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' '.' '.' '.' '.' '.' 'B' '#']\n",
      " ['#' '#' '#' '.' '#' '.' '#' 'C' '#' 'D' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' 'A' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' '.' '.' '.' '.' 'D' 'B' '#']\n",
      " ['#' '#' '#' '.' '#' '.' '#' 'C' '#' '.' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' 'A' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' '.' '.' 'A' '.' 'D' 'B' '#']\n",
      " ['#' '#' '#' '.' '#' '.' '#' 'C' '#' '.' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' '.' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' '.' '.' '.' '.' 'D' 'B' '#']\n",
      " ['#' '#' '#' 'A' '#' '.' '#' 'C' '#' '.' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'D' '#' 'C' '#' '.' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' 'B' '.' '.' '.' 'D' '.' '.' '.' 'D' 'B' '#']\n",
      " ['#' '#' '#' 'A' '#' '.' '#' 'C' '#' '.' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' '.' '#' 'C' '#' '.' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' '.' '.' '.' '.' 'D' '.' '.' '.' 'D' 'B' '#']\n",
      " ['#' '#' '#' 'A' '#' '.' '#' 'C' '#' '.' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'B' '#' 'C' '#' '.' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' '.' '.' '.' '.' 'D' '.' '.' '.' '.' 'B' '#']\n",
      " ['#' '#' '#' 'A' '#' '.' '#' 'C' '#' '.' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'B' '#' 'C' '#' 'D' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' 'B' '#']\n",
      " ['#' '#' '#' 'A' '#' '.' '#' 'C' '#' 'D' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'B' '#' 'C' '#' 'D' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "[['#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#' '#']\n",
      " ['#' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '#']\n",
      " ['#' '#' '#' 'A' '#' 'B' '#' 'C' '#' 'D' '#' '#' '#']\n",
      " [' ' ' ' '#' 'A' '#' 'B' '#' 'C' '#' 'D' '#' ' ' ' ']\n",
      " [' ' ' ' '#' '#' '#' '#' '#' '#' '#' '#' '#' ' ' ' ']]\n",
      "-12599\n"
     ]
    }
   ],
   "source": [
    "env = AmphipodEnvironment(raw_test)\n",
    "state = env.state_to_str()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action_space = q_table[state]    \n",
    "        \n",
    "    action = list(action_space.keys())[np.argmax(list(action_space.values()))]\n",
    "    \n",
    "    state, reward, done, _ = env.step(action) \n",
    "    total_reward = total_reward + reward\n",
    "    print(env.state)\n",
    "    \n",
    "print(total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
